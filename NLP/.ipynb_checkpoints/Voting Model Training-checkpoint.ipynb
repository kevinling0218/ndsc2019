{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sklearn modules\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import FunctionTransformer,OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Classifiers\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categories and category feature columns\n",
    "categories = ['beauty', 'fashion', 'mobile']\n",
    "category_feature_columns = {'beauty':[ 'Brand', 'Colour_group', 'Benefits', 'Product_texture', 'Skin_type'], \n",
    "                   'fashion': ['Collar Type', 'Sleeves', 'Pattern', 'Fashion Trend', 'Clothing Material'],\n",
    "                   'mobile': ['Operating System', 'Features',\n",
    "       'Network Connections', 'Memory RAM', 'Brand', 'Warranty Period',\n",
    "       'Storage Capacity', 'Color Family', 'Phone Model', 'Camera',\n",
    "       'Phone Screen Size']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DenseTransformer(TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_data_title(df, label, test_size):\n",
    "    '''Prepare training and test data'''\n",
    "    df = df[['title', label]]\n",
    "    df = df.dropna()\n",
    "    X = df['title']\n",
    "    y = df[label]\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=test_size)\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(df):\n",
    "    return df['title_processed']\n",
    "def get_language(df):\n",
    "    return df['language_processed'].astype(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train the voting model\n",
    "def train_test_voting_model(category, target_column, X_train, y_train):\n",
    "    voting_model = build_voting_model()\n",
    "    voting_model.fit(X_train, y_train)\n",
    "    # Evaluation\n",
    "    best_params = voting_model.best_params_\n",
    "    predicted = voting_model.predict(X_test)\n",
    "    #print('Voting Classifiers: ', voting_model.get_params())\n",
    "    print('Best Parameters: ', best_params)\n",
    "    print('Train Set Accuracy: ', round(voting_model.best_score_, 2))\n",
    "    print('Test Set Accuracy: ', round(np.mean(predicted == y_test), 2))\n",
    "    \n",
    "    with open ('voting_clf_23032019_{}_{}.pkl'.format(category, target_column), 'wb') as f:\n",
    "        pickle.dump(voting_model, f)\n",
    "        \n",
    "    return voting_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_voting_model():\n",
    "    \"\"\"\n",
    "    Build the Voting model\n",
    "    \"\"\" \n",
    "\n",
    "    LOG_clf = LogisticRegression(solver = 'lbfgs', multi_class = 'multinomial', random_state = 1)\n",
    "    RF_clf = RandomForestClassifier(n_estimators = 20, random_state = 1)\n",
    "    NB_clf = GaussianNB()\n",
    "    MLP_clf = MLPClassifier(alpha = 1)\n",
    "    SVC_clf = SVC() # Using RBF Kernel\n",
    "    ADA_clf = AdaBoostClassifier()\n",
    "    #QDA_clf = QuadraticDiscriminantAnalysis()\n",
    "    XGB_clf = XGBClassifier(n_estimators=20, silent = False, objective = 'softmax')\n",
    "    SGD_clf = SGDClassifier(loss='modified_huber', max_iter=1000, tol=1e-3, class_weight='balanced')\n",
    "    \n",
    "    vot_clf = VotingClassifier(estimators = [\n",
    "        ('LOG_clf', LOG_clf),\n",
    "#         ('RF_clf', RF_clf),\n",
    "        ('NB_clf', NB_clf),\n",
    "        ('MLP_clf', MLP_clf),\n",
    "        ('SVC_clf', SVC_clf),\n",
    "        ('ADA_clf', ADA_clf),\n",
    "#         ('QDA_clf', QDA_clf),\n",
    "#         ('XGB_clf', XGB_clf),\n",
    "        ('SGD_clf', SGD_clf)\n",
    "    ])\n",
    "\n",
    "\n",
    "    text_clf = Pipeline([\n",
    "        ('vect', CountVectorizer(token_pattern='\\\\b\\\\w+\\\\b')),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('to_dense', DenseTransformer()),\n",
    "        ('vot_clf', vot_clf)])\n",
    "    # Define parameters for grid search\n",
    "    parameters = {'vect__ngram_range': [(1, 2)],\n",
    "                'tfidf__use_idf': (True, False)\n",
    "                 }\n",
    "\n",
    "\n",
    "    # Grid search across our parameters, scoring by accuracy\n",
    "    gs_clf = GridSearchCV(estimator=text_clf, param_grid=parameters, verbose = 100, cv= ShuffleSplit(test_size=0.01, n_splits=1)\n",
    "                          , iid=False, n_jobs=2, pre_dispatch = '2*n_jobs', scoring='accuracy')\n",
    "\n",
    "    return gs_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_beauty_train = pd.read_csv('../data/processed/beauty_train_processed.csv')\n",
    "# df_beauty_train = df_beauty_train.head(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing for column: Brand\n",
      "Fitting 1 folds for each of 2 candidates, totalling 2 fits\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "Memmapping (shape=(235746,), dtype=int64) to new file /var/folders/z3/gv1sb1m56275_y6ws_wx4v240000gn/T/joblib_memmapping_folder_614_2705663489/614-4932260696-12e1ee653d7844c9b3b6d0ca65abb31e.pkl\n",
      "Pickling array (shape=(235746,), dtype=object).\n",
      "Memmapping (shape=(235746,), dtype=int64) to new file /var/folders/z3/gv1sb1m56275_y6ws_wx4v240000gn/T/joblib_memmapping_folder_614_2705663489/614-4932260696-d2ead7614331402da7a66244e4a0f6f4.pkl\n",
      "Memmapping (shape=(235746,), dtype=int64) to new file /var/folders/z3/gv1sb1m56275_y6ws_wx4v240000gn/T/joblib_memmapping_folder_614_2705663489/614-4932260696-4e7671ac6f06482aab2a9da0d6cc412a.pkl\n",
      "Memmapping (shape=(235746,), dtype=float64) to new file /var/folders/z3/gv1sb1m56275_y6ws_wx4v240000gn/T/joblib_memmapping_folder_614_2705663489/614-4932260696-c59a284dde2641f3adc80fd48f679d20.pkl\n",
      "Memmapping (shape=(235746,), dtype=int64) to new file /var/folders/z3/gv1sb1m56275_y6ws_wx4v240000gn/T/joblib_memmapping_folder_614_2705663489/614-4932260696-e28270548aec4bb0a094bad7ebcf7f22.pkl\n",
      "Memmapping (shape=(233388,), dtype=int64) to new file /var/folders/z3/gv1sb1m56275_y6ws_wx4v240000gn/T/joblib_memmapping_folder_614_2705663489/614-4932260696-a02b19b1e0604e30ae3c4967807ca48e.pkl\n",
      "Pickling array (shape=(2358,), dtype=int64).\n",
      "Memmapping (shape=(235746,), dtype=int64) to old file /var/folders/z3/gv1sb1m56275_y6ws_wx4v240000gn/T/joblib_memmapping_folder_614_2705663489/614-4932260696-12e1ee653d7844c9b3b6d0ca65abb31e.pkl\n",
      "Pickling array (shape=(235746,), dtype=object).\n",
      "Memmapping (shape=(235746,), dtype=int64) to new file /var/folders/z3/gv1sb1m56275_y6ws_wx4v240000gn/T/joblib_memmapping_folder_614_2705663489/614-4932260696-dd277765ea9a476aa458198a74e28e78.pkl\n",
      "Memmapping (shape=(235746,), dtype=int64) to old file /var/folders/z3/gv1sb1m56275_y6ws_wx4v240000gn/T/joblib_memmapping_folder_614_2705663489/614-4932260696-4e7671ac6f06482aab2a9da0d6cc412a.pkl\n",
      "Memmapping (shape=(235746,), dtype=float64) to old file /var/folders/z3/gv1sb1m56275_y6ws_wx4v240000gn/T/joblib_memmapping_folder_614_2705663489/614-4932260696-c59a284dde2641f3adc80fd48f679d20.pkl\n",
      "Memmapping (shape=(235746,), dtype=int64) to new file /var/folders/z3/gv1sb1m56275_y6ws_wx4v240000gn/T/joblib_memmapping_folder_614_2705663489/614-4932260696-010a4351512243a18fcefa5952ca8f3f.pkl\n",
      "Memmapping (shape=(233388,), dtype=int64) to old file /var/folders/z3/gv1sb1m56275_y6ws_wx4v240000gn/T/joblib_memmapping_folder_614_2705663489/614-4932260696-a02b19b1e0604e30ae3c4967807ca48e.pkl\n",
      "Pickling array (shape=(2358,), dtype=int64).\n"
     ]
    }
   ],
   "source": [
    "beauty_feature_columns = [ 'Brand', 'Colour_group', 'Benefits', 'Product_texture', 'Skin_type']\n",
    "\n",
    "# Add lanaguage to title\n",
    "df_beauty_train['title'] = df_beauty_train[['title_processed', 'language_processed']].apply(lambda x: ' '.join(x), axis=1)\n",
    "\n",
    "\n",
    "for column in beauty_feature_columns:\n",
    "    print (\"Now processing for column:\", column)\n",
    "    # Unpack data\n",
    "    X_train,X_test,y_train,y_test = train_test_data_title(df_beauty_train, column, 0.01)\n",
    "    voting_model = train_test_voting_model('beauty', column, X_train, y_train)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
